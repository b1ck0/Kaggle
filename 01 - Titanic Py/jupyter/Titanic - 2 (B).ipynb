{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    \n",
    "    def get_title(row):\n",
    "        step1 = row['Name'].split(',', 1)\n",
    "        step2 = step1[1].split('.', 1)\n",
    "    \n",
    "        return step2[0].strip()\n",
    "\n",
    "    def family_size(row):\n",
    "        if row['SibSp'] == 0 and row['Parch'] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return row['SibSp'] + row['Parch'] + 1\n",
    "        \n",
    "    ticket_dict = df['Ticket'].value_counts()\n",
    "\n",
    "    def get_same_ticket(ticket, dictionary):\n",
    "        return dictionary[ticket]\n",
    "    \n",
    "    df['Title']       = df.apply(lambda x: get_title(x), axis=1)\n",
    "    df['Group Size']  = df['Ticket'].apply(lambda x: get_same_ticket(x, ticket_dict))\n",
    "    df['Family Size'] = df.apply(lambda x: family_size(x), axis=1)\n",
    "    \n",
    "    # calculating the fare per person, otherwise in the dataset I have the total fare per ticket\n",
    "    df.loc[:,'Fare']  = df.loc[:,'Fare'] / df.loc[:,'Group Size']\n",
    "    \n",
    "    #df['Age'].fillna(df.groupby(['Pclass', 'Sex'])['Age'].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_ready(df):\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    \n",
    "    features = ['Age', 'Pclass', 'Sex', 'Family Size', 'Group Size', 'Title', 'Ticket']\n",
    "    target   = 'Survived'\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    for column in X.columns:\n",
    "        if column != 'Age':\n",
    "            X.loc[:,column], junk = X.loc[:,column].factorize()\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=379582)\n",
    "\n",
    "def infer_ready(df):\n",
    "    features = ['Age','Pclass', 'Sex', 'Family Size', 'Group Size', 'Title', 'Ticket']\n",
    "    \n",
    "    X = df[features]\n",
    "    \n",
    "    for column in X.columns:\n",
    "        if column != 'Age':\n",
    "            X.loc[:,column], junk = X.loc[:,column].factorize()\n",
    "    \n",
    "    return X\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, infer):\n",
    "\n",
    "    from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    gboost = GradientBoostingClassifier(n_estimators=40, learning_rate=0.09)\n",
    "\n",
    "    gboost.fit(X_train, y_train)\n",
    "\n",
    "    predictions = gboost.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    \n",
    "    submissions = gboost.predict(infer)\n",
    "    \n",
    "    submission = pd.DataFrame(index=infer.index)\n",
    "    submission['Survived'] = submissions\n",
    "    submission['Survived'] = submission['Survived'].astype('int32')\n",
    "    \n",
    "    submission.to_csv('submission-03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../input/train.csv')\n",
    "infer_csv = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv.set_index('PassengerId', inplace=True)\n",
    "infer_csv.set_index('PassengerId', inplace=True)\n",
    "df = pd.concat([train_csv, infer_csv], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a model to predict a passenger's age using the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: -118.42889, std: 11.85648, params: {'learning_rate': 0.09, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 40, 'subsample': 1.0},\n",
       "  mean: -119.15500, std: 12.49263, params: {'learning_rate': 0.09, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 60, 'subsample': 1.0},\n",
       "  mean: -119.31371, std: 12.60655, params: {'learning_rate': 0.09, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 65, 'subsample': 1.0},\n",
       "  mean: -118.45483, std: 12.02994, params: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 40, 'subsample': 1.0},\n",
       "  mean: -119.20567, std: 12.54854, params: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 60, 'subsample': 1.0},\n",
       "  mean: -119.31248, std: 12.68117, params: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 65, 'subsample': 1.0},\n",
       "  mean: -156.29071, std: 9.29951, params: {'learning_rate': 0.011, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 40, 'subsample': 1.0},\n",
       "  mean: -143.21206, std: 9.57521, params: {'learning_rate': 0.011, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 60, 'subsample': 1.0},\n",
       "  mean: -140.70624, std: 9.68300, params: {'learning_rate': 0.011, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 65, 'subsample': 1.0}],\n",
       " {'learning_rate': 0.09,\n",
       "  'max_depth': 5,\n",
       "  'min_samples_leaf': 10,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 40,\n",
       "  'subsample': 1.0},\n",
       " -118.42888643402762)"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df['Age'].isnull() == False]\n",
    "infer = df[df['Age'].isnull() == True]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "features = ['Title', 'Group Size', 'Pclass']\n",
    "target = 'Age'\n",
    "\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "\n",
    "ukn = infer[features]\n",
    "\n",
    "for column in X.columns:\n",
    "    X[column], junk = X[column].factorize()\n",
    "    \n",
    "for column in ukn.columns:\n",
    "    ukn[column], junk = ukn[column].factorize()\n",
    "\n",
    "params = {\n",
    "    'n_estimators'      : [40, 60, 65],\n",
    "    'learning_rate'     : [0.09, 0.1, 0.011],\n",
    "    'max_depth'         : [5],\n",
    "    'subsample'         : [1.0],\n",
    "    'min_samples_split' : [2],\n",
    "    'min_samples_leaf'  : [10],\n",
    "}\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=369582)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model, \n",
    "    params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    iid=False,\n",
    "    cv=5\n",
    ")\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "    random_state=369582,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.0992,\n",
    "    min_samples_leaf=10,\n",
    "    n_estimators=65\n",
    ")\n",
    "\n",
    "model.fit(X,y)\n",
    "\n",
    "predictions = model.predict(ukn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[ukn.index,'Age'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Prediction of 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = df[df['Survived'].isnull() == False].index\n",
    "index2 = df[df['Survived'].isnull() == True].index\n",
    "\n",
    "train_csv = df.loc[index1,:]\n",
    "infer_csv = df.loc[index2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = ml_ready(train_csv)\n",
    "X = infer_ready(infer_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.90      0.86       162\n",
      "        1.0       0.81      0.70      0.75       106\n",
      "\n",
      "avg / total       0.82      0.82      0.81       268\n",
      "\n",
      "[[145  17]\n",
      " [ 32  74]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(X_train, X_test, y_train, y_test, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently no influence on the model, just for benchmark info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.81228, std: 0.02448, params: {'learning_rate': 0.09, 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 35, 'subsample': 1.0},\n",
       "  mean: 0.80588, std: 0.02575, params: {'learning_rate': 0.09, 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 40, 'subsample': 1.0},\n",
       "  mean: 0.80585, std: 0.02382, params: {'learning_rate': 0.09, 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 45, 'subsample': 1.0}],\n",
       " {'learning_rate': 0.09,\n",
       "  'max_depth': 3,\n",
       "  'max_features': None,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 35,\n",
       "  'subsample': 1.0},\n",
       " 0.8122781362007168)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "params = {\n",
    "    'n_estimators'      : [35,40,45],\n",
    "    'learning_rate'     : [0.09],\n",
    "    'max_depth'         : [3],\n",
    "    'subsample'         : [1.0],\n",
    "    'min_samples_split' : [2],\n",
    "    'min_samples_leaf'  : [1],\n",
    "    'max_features'      : [None]\n",
    "}\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=369582)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model, \n",
    "    params,\n",
    "    scoring='accuracy',\n",
    "    iid=False,\n",
    "    cv=5\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
