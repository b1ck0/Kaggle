{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('max_rows', 150)\n",
    "pd.set_option('max_info_rows', 150)\n",
    "pd.set_option('max_info_columns', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../input/application_train.csv.zip', compression='infer', index_col='SK_ID_CURR')\n",
    "infer_csv = pd.read_csv('../input/application_test.csv.zip', compression='infer', index_col='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rows(df):\n",
    "    # removing 4 rows\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # removing 2 rows\n",
    "    df = df[df['NAME_FAMILY_STATUS'] != 'Unknown']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    columns_to_drop = [\n",
    "        'FLAG_DOCUMENT_2',  # only 15 people provided this document and 4 are approved (nothing to learn from this feature)\n",
    "        'FLAG_DOCUMENT_4',  # only 25 people provided this document and all are approved (high bias toward 1)\n",
    "        'FLAG_DOCUMENT_7',  # only 59 people provided this document and 3 are approved (high bias towards 0)\n",
    "        'FLAG_DOCUMENT_10', # only 7 people provided this document and None are approved (high bias towards 0)\n",
    "        'FLAG_DOCUMENT_12', # only 2 people provided this document and None are approved (high bias towards 0)\n",
    "        'FLAG_DOCUMENT_17', # only 82 people provided this document and 2 are approved (high bias towards 0)\n",
    "        'FLAG_MOBIL',       # only 1 didn't provide this info and he is rejected (high bias towards 0)\n",
    "    ]\n",
    "    \n",
    "    # removing all columns which contain AVG, MEDI and MODE in their names\n",
    "    for column in df.columns:\n",
    "        words = column.split('_')\n",
    "        if (words[-1].lower() == 'avg') or (words[-1].lower() == 'medi') or (words[-1].lower() == 'mode'):\n",
    "            columns_to_drop.append(column)\n",
    "    \n",
    "    # performing the drop\n",
    "    df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bureau_data(index):\n",
    "    '''\n",
    "    Generates the following features for each applicant:\n",
    "    \n",
    "    Input:\n",
    "    df - bureau dataset\n",
    "    index - applicants on which we want to subset the bureau dataset (trainig, validation, testing)\n",
    "    \n",
    "    Output: \n",
    "    dataframe with all new features and index 'SK_ID_CURR'\n",
    "    \n",
    "    CNT_ACTIVE_LOANS  - number of active loans with other institutions\n",
    "    CNT_BAD_LOANS     - number of bad loans with other institutions\n",
    "    CNT_CLOSED_LOANS  - number of closed loans with other institutions\n",
    "    CNT_SOLD_LOANS    - number of loans sold by the other institutions\n",
    "    \n",
    "    AMT_ACTIVE_LOANS  - total outstanding loans amount with other istitutions\n",
    "    AMT_BAD_LOANS     - total bad loans amount with other institutions\n",
    "    AMT_CLOSED_LOANS  - total amount of closed loans with other institutions\n",
    "    AMT_SOLD_LOANS    - total amount of sold loans with other institutions\n",
    "    \n",
    "    DAYS_OUTSTANDING  - days due of the loan which ends last\n",
    "    DAYS_RECENT_CLOSE - days since the applicant closed his most recent loan\n",
    "    \n",
    "    AMT_OUTSTD_0_YEAR - outstanding amount due less than a year\n",
    "    AMT_OUTSTD_1_YEAR - outstanding amount due within [1, 2) years\n",
    "    AMT_OUTSTD_2_YEAR - outstanding amount due within [2, 3) years\n",
    "    AMT_OUTSTD_3_YEAR - outstanding amount due within [3, 4) years\n",
    "    AMT_OUTSTD_4_YEAR - outstanding amount due within [4, 5) years\n",
    "    AMT_OUTSTD_5_YEAR - outstanding amount due within [5, inf) years\n",
    "    \n",
    "    CNT_PROLONGED     - total number of prolongations for active credits\n",
    "    '''\n",
    "    def column_labels_bureau():\n",
    "        '''\n",
    "        Creates nested dictionaries used for renaming the dfs' column names\n",
    "        '''\n",
    "        labels = {}\n",
    "\n",
    "        labels['num_credits'] = {\n",
    "              'Active'   : 'CNT_ACTIVE_LOANS',\n",
    "              'Bad debt' : 'CNT_BAD_LOANS',\n",
    "              'Closed'   : 'CNT_CLOSED_LOANS',\n",
    "              'Sold'     : 'CNT_SOLD_LOANS'\n",
    "             }\n",
    "\n",
    "        labels['amt_credits'] = {\n",
    "              'Active'   : 'AMT_ACTIVE_LOANS',\n",
    "              'Bad debt' : 'AMT_BAD_LOANS',\n",
    "              'Closed'   : 'AMT_CLOSED_LOANS',\n",
    "              'Sold'     : 'AMT_SOLD_LOANS'\n",
    "             }\n",
    "\n",
    "        labels['max_days_active'] = {\n",
    "              'Active'   : 'DAYS_OUTSTANDING',\n",
    "              'Bad debt' : 'DROP_1',\n",
    "              'Closed'   : 'DROP_2',\n",
    "              'Sold'     : 'DROP_3'\n",
    "             }\n",
    "\n",
    "        labels['max_days_closed'] = {\n",
    "              'Active'   : 'DROP_4',\n",
    "              'Bad debt' : 'DROP_5',\n",
    "              'Closed'   : 'DAYS_RECENT_CLOSE',\n",
    "              'Sold'     : 'DROP_6'\n",
    "             }\n",
    "\n",
    "        labels['cnt_prolonged'] = {\n",
    "              'Active'   : 'CNT_PROLONGED',\n",
    "              'Bad debt' : 'DROP_7',\n",
    "              'Closed'   : 'DROP_8',\n",
    "              'Sold'     : 'DROP_9'\n",
    "             }\n",
    "        \n",
    "        labels['amt_active_overdue'] = {\n",
    "            'Active'   : 'AMT_ACTIVE_OVERDUE',\n",
    "            'Bad debt' : 'DROP_10',\n",
    "            'Closed'   : 'DROP_11',\n",
    "            'Sold'     : 'DROP_12'\n",
    "        }\n",
    "        \n",
    "        labels['max_days_overdue'] = {\n",
    "            'Active'   : 'DAYS_ACTIVE_OVERDUE',\n",
    "            'Bad debt' : 'DROP_13',\n",
    "            'Closed'   : 'DROP_14',\n",
    "            'Sold'     : 'DROP_15'\n",
    "        }\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    df = pd.read_csv('../input/bureau.csv.zip', compression='infer')\n",
    "    \n",
    "    # taking a subset of the bureau dataset\n",
    "    df = df.loc[index,:]\n",
    "    \n",
    "    num_credits = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns='CREDIT_ACTIVE', \n",
    "            values='SK_ID_BUREAU', \n",
    "            aggfunc='count', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    amt_credits = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns='CREDIT_ACTIVE', \n",
    "            values='AMT_CREDIT_SUM_DEBT', \n",
    "            aggfunc='sum', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    max_days_active = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns='CREDIT_ACTIVE', \n",
    "            values='DAYS_CREDIT_ENDDATE', \n",
    "            aggfunc='max', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    max_days_closed = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns='CREDIT_ACTIVE', \n",
    "            values='DAYS_ENDDATE_FACT', \n",
    "            aggfunc='max', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    cnt_prolonged = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns='CREDIT_ACTIVE', \n",
    "            values='CNT_CREDIT_PROLONG', \n",
    "            aggfunc='sum',\n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    amt_active_overdue = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "        index='SK_ID_CURR', \n",
    "        columns='CREDIT_ACTIVE', \n",
    "        values='AMT_CREDIT_SUM_OVERDUE', \n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    max_days_overdue = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "        index='SK_ID_CURR', \n",
    "        columns='CREDIT_ACTIVE', \n",
    "        values='CREDIT_DAY_OVERDUE', \n",
    "        aggfunc='max',\n",
    "        fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    # credit amounts due for the next 5+ years\n",
    "    df.loc[:,'YEARS_ENDDATE'] = df.loc[:,'DAYS_CREDIT_ENDDATE']//365\n",
    "    df['YEARS_ENDDATE'].fillna(0,inplace=True)\n",
    "    df['YEARS_ENDDATE'].clip(lower=0, upper=5,inplace=True)\n",
    "    \n",
    "    amt_credits_by_year = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns=['CREDIT_ACTIVE','YEARS_ENDDATE'], \n",
    "            values='AMT_CREDIT_SUM_DEBT', \n",
    "            aggfunc='sum', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    amt_credits_by_year.set_index('SK_ID_CURR', inplace=True)\n",
    "    columns = amt_credits_by_year.columns[:6]\n",
    "    amt_credits_by_year = amt_credits_by_year[columns] # take only the first 6 columns the rest is garbage\n",
    "    del columns  \n",
    "    \n",
    "    # number of credits in the past year\n",
    "    df.loc[:,'YEARS_OPEN_DATE'] = df.loc[:,'DAYS_CREDIT']//365\n",
    "    df['YEARS_OPEN_DATE'].fillna(0,inplace=True)\n",
    "    df['YEARS_OPEN_DATE'].clip(lower=-5, upper=0,inplace=True)\n",
    "    \n",
    "    num_active_credits_past_years = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns=['CREDIT_ACTIVE','YEARS_OPEN_DATE'], \n",
    "            values='SK_ID_BUREAU', \n",
    "            aggfunc='count', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    num_active_credits_past_years.set_index('SK_ID_CURR', inplace=True)\n",
    "    columns = num_active_credits_past_years.columns[:6]\n",
    "    num_active_credits_past_years = num_active_credits_past_years[columns] # take only the first 6 columns the rest is garbage\n",
    "    del columns\n",
    "    \n",
    "    num_credits.set_index('SK_ID_CURR', inplace=True)\n",
    "    amt_credits.set_index('SK_ID_CURR', inplace=True)\n",
    "    max_days_active.set_index('SK_ID_CURR', inplace=True)\n",
    "    max_days_closed.set_index('SK_ID_CURR', inplace=True)\n",
    "    cnt_prolonged.set_index('SK_ID_CURR', inplace=True)\n",
    "    amt_active_overdue.set_index('SK_ID_CURR', inplace=True)\n",
    "    max_days_overdue.set_index('SK_ID_CURR', inplace=True)\n",
    "\n",
    "    labels = column_labels_bureau()\n",
    "    \n",
    "    num_credits.rename(columns=labels['num_credits'], inplace=True)\n",
    "    amt_credits.rename(columns=labels['amt_credits'], inplace=True)\n",
    "    max_days_active.rename(columns=labels['max_days_active'], inplace=True)\n",
    "    max_days_closed.rename(columns=labels['max_days_closed'], inplace=True)\n",
    "    cnt_prolonged.rename(columns=labels['cnt_prolonged'], inplace=True)\n",
    "    amt_active_overdue.rename(columns=labels['amt_active_overdue'], inplace=True)\n",
    "    max_days_overdue.rename(columns=labels['max_days_overdue'], inplace=True)\n",
    "        \n",
    "    amt_credits_by_year.columns = [\n",
    "        'AMT_OUTSTD_0_YEAR', \n",
    "        'AMT_OUTSTD_1_YEAR', \n",
    "        'AMT_OUTSTD_2_YEAR', \n",
    "        'AMT_OUTSTD_3_YEAR',\n",
    "        'AMT_OUTSTD_4_YEAR',\n",
    "        'AMT_OUTSTD_5_YEAR'\n",
    "    ]\n",
    "    \n",
    "    num_active_credits_past_years.columns = [\n",
    "        'CNT_ACT_LOANS_OPEN_5_YEAR',\n",
    "        'CNT_ACT_LOANS_OPEN_4_YEAR',\n",
    "        'CNT_ACT_LOANS_OPEN_3_YEAR',\n",
    "        'CNT_ACT_LOANS_OPEN_2_YEAR',\n",
    "        'CNT_ACT_LOANS_OPEN_1_YEAR',\n",
    "        'CNT_ACT_LOANS_OPEN_0_YEAR',\n",
    "    ]\n",
    "    \n",
    "    transformed = pd.DataFrame(index=num_credits.index)\n",
    "    \n",
    "    transformed = transformed.join(\n",
    "        [\n",
    "            num_credits,\n",
    "            amt_credits,\n",
    "            max_days_active,\n",
    "            max_days_closed,\n",
    "            amt_credits_by_year,\n",
    "            cnt_prolonged,\n",
    "            num_active_credits_past_years,\n",
    "            amt_active_overdue,\n",
    "            max_days_overdue\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    for column in transformed:\n",
    "        words = column.split('_')\n",
    "        if words[0] == 'DROP':\n",
    "            columns_to_drop.append(column)\n",
    "            \n",
    "    transformed.drop(columns_to_drop, inplace=True, axis=1)\n",
    "    \n",
    "    del df\n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_prev_data(index):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    def column_labels_prev():\n",
    "        '''\n",
    "        Creates nested dictionaries used for renaming the dfs' column names\n",
    "        '''\n",
    "        labels = {}\n",
    "\n",
    "        labels['num_credits'] = {\n",
    "              'Approved'     : 'CNT_APPROVED_LOANS',\n",
    "              'Canceled'     : 'CNT_CANCELED_LOANS',\n",
    "              'Refused'      : 'CNT_REFUSED_LOANS',\n",
    "              'Unused offer' : 'CNT_UNUSED_LOANS'\n",
    "             }\n",
    "        \n",
    "        labels['last_decision'] = {\n",
    "              'Approved'     : 'DAYS_LAST_APPROVAL',\n",
    "              'Canceled'     : 'DAYS_LAST_CANCELED',\n",
    "              'Refused'      : 'DAYS_LAST_REFUSAL',\n",
    "              'Unused offer' : 'DAYS_LAST_UNUSED'\n",
    "             }\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    df = pd.read_csv('../input/previous_application.csv.zip', compression='infer')\n",
    "    \n",
    "    df = df.loc[index,:]\n",
    "    \n",
    "    num_credits = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns='NAME_CONTRACT_STATUS', \n",
    "            values='SK_ID_PREV', \n",
    "            aggfunc='count', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    last_decision = pd.DataFrame(\n",
    "        df.pivot_table(\n",
    "            index='SK_ID_CURR', \n",
    "            columns='NAME_CONTRACT_STATUS', \n",
    "            values='DAYS_DECISION', \n",
    "            aggfunc='max', \n",
    "            fill_value=0\n",
    "        ).to_records()\n",
    "    )\n",
    "    \n",
    "    num_credits.set_index('SK_ID_CURR', inplace=True)\n",
    "    last_decision.set_index('SK_ID_CURR', inplace=True)\n",
    "    \n",
    "    labels = column_labels_prev()\n",
    "    \n",
    "    num_credits.rename(columns=labels['num_credits'], inplace=True)\n",
    "    last_decision.rename(columns=labels['last_decision'], inplace=True)\n",
    "    \n",
    "    transformed = pd.DataFrame(index=num_credits.index)\n",
    "    \n",
    "    transformed = transformed.join(\n",
    "        [\n",
    "            num_credits,\n",
    "            last_decision,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    del df\n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_columns(df):\n",
    "    \n",
    "    float_columns = [\n",
    "        'EXT_SOURCE_1', \n",
    "        'EXT_SOURCE_2', \n",
    "        'EXT_SOURCE_3', \n",
    "        'REGION_POPULATION_RELATIVE', \n",
    "        'REGION_RATING_CLIENT',\n",
    "        'REGION_RATING_CLIENT_W_CITY',\n",
    "        'RATIO_DEBT',\n",
    "        'RATIO_DEBT_TOT',\n",
    "        'RATIO_REPAYMENT'\n",
    "    ]\n",
    "    \n",
    "    for column in df.columns:\n",
    "        \n",
    "        # converting float to int\n",
    "        if df[column].dtype == 'float32' or df[column].dtype == 'float64':\n",
    "            if column not in float_columns:\n",
    "                df[column] = df[column].astype('int32') # int32 prefered from Tensorflow\n",
    "        \n",
    "        # factorizing only the columns containing text\n",
    "        elif df[column].dtype == 'object':\n",
    "            df[column], junk = pd.factorize(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    \n",
    "    if 'CNT_BAD_LOANS' not in df.columns:\n",
    "        df.loc[:,'CNT_BAD_LOANS'] = 0\n",
    "    \n",
    "    df.loc[:,'TOTAL_DEBT'] = df.loc[:,'AMT_ACTIVE_LOANS'] + df.loc[:,'AMT_CREDIT']\n",
    "    df.loc[:,'RATIO_DEBT'] = df.loc[:,'AMT_CREDIT'] / df.loc[:,'AMT_INCOME_TOTAL']\n",
    "    df.loc[:,'RATIO_DEBT_TOT'] = df.loc[:,'TOTAL_DEBT'] / df.loc[:,'AMT_INCOME_TOTAL']\n",
    "    df.loc[:,'RATIO_REPAYMENT'] = df.loc[:,'CNT_CLOSED_LOANS'] / (\n",
    "                                                            df.loc[:,'CNT_ACTIVE_LOANS'] + \n",
    "                                                            df.loc[:,'CNT_BAD_LOANS'] + \n",
    "                                                            df.loc[:,'CNT_CLOSED_LOANS'] + \n",
    "                                                            df.loc[:,'CNT_SOLD_LOANS']\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = delete_rows(train_csv)\n",
    "\n",
    "drop_columns(train_csv)      \n",
    "drop_columns(infer_csv)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasil\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:82: FutureWarning: 'SK_ID_CURR' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  grouped = data.groupby(keys, observed=dropna)\n"
     ]
    }
   ],
   "source": [
    "train_csv.fillna(0, inplace=True)\n",
    "infer_csv.fillna(0, inplace=True)\n",
    "\n",
    "train, valid = train_test_split(train_csv, test_size=0.33, random_state=379582)\n",
    "\n",
    "bureau_train = transform_bureau_data(train.index)\n",
    "bureau_valid = transform_bureau_data(valid.index)\n",
    "bureau_infer = transform_bureau_data(infer_csv.index)\n",
    "\n",
    "prev_train = transform_prev_data(train.index)\n",
    "prev_valid = transform_prev_data(valid.index)\n",
    "prev_infer = transform_prev_data(infer_csv.index)\n",
    "\n",
    "train = train.join([bureau_train, prev_train])\n",
    "valid = valid.join([bureau_valid, prev_valid])\n",
    "infer_csv = infer_csv.join([bureau_infer, prev_infer])\n",
    "\n",
    "del bureau_infer, bureau_train, bureau_valid, prev_train, prev_valid, prev_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(train)\n",
    "transform_data(valid)\n",
    "transform_data(infer_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "valid.fillna(0, inplace=True)\n",
    "infer_csv.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_columns(train)\n",
    "format_columns(valid)\n",
    "format_columns(infer_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(df):\n",
    "    # all people with more than 4 children are cliped to 4\n",
    "    df['CNT_CHILDREN'].clip(lower=0, upper=4, inplace=True)\n",
    "    \n",
    "    # all people with more than 6 fam. members are cliped to 6\n",
    "    df['CNT_FAM_MEMBERS'].clip(lower=0, upper=6, inplace=True) \n",
    "    \n",
    "    df['AMT_REQ_CREDIT_BUREAU_HOUR'].clip(lower=0, upper=2, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_DAY'].clip(lower=0, upper=2, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_WEEK'].clip(lower=0, upper=2, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_MON'].clip(lower=0, upper=10, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_QRT'].clip(lower=0, upper=6, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_YEAR'].clip(lower=0, upper=6, inplace=True)\n",
    "    df['OBS_30_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=17, inplace=True)\n",
    "    df['OBS_60_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=17, inplace=True)\n",
    "    df['DEF_30_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=5, inplace=True)\n",
    "    df['DEF_60_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=4, inplace=True)\n",
    "    \n",
    "    df['CNT_ACTIVE_LOANS'].clip(lower=0, upper=15, inplace=True)\n",
    "    \n",
    "    # lumping rare income types into a single category\n",
    "    index1 = df[df['NAME_INCOME_TYPE'] == 'Businessman'].index\n",
    "    index2 = df[df['NAME_INCOME_TYPE'] == 'Maternity leave'].index\n",
    "    index3 = df[df['NAME_INCOME_TYPE'] == 'Student'].index\n",
    "    index4 = df[df['NAME_INCOME_TYPE'] == 'Unemployed'].index\n",
    "    \n",
    "    df.loc[index1,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    df.loc[index2,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    df.loc[index3,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    df.loc[index4,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    \n",
    "def quantize(df, bins=10):\n",
    "    features_to_quantazie = [\n",
    "        'AMT_INCOME_TOTAL',\n",
    "        'AMT_CREDIT',\n",
    "        'AMT_ANNUITY',\n",
    "        'AMT_GOODS_PRICE',\n",
    "        'DAYS_BIRTH',\n",
    "        'DAYS_ID_PUBLISH',\n",
    "        'DAYS_LAST_PHONE_CHANGE',\n",
    "        'DAYS_REGISTRATION',\n",
    "        'OWN_CAR_AGE',\n",
    "        'REGION_POPULATION_RELATIVE'\n",
    "    ]\n",
    "    \n",
    "    for feature in features_to_quantazie:\n",
    "        if feature != 'DAYS_LAST_PHONE_CHANGE':\n",
    "            df[feature] = pd.qcut(df[feature], bins, labels=False)\n",
    "        else:\n",
    "            df[feature] = pd.qcut(df[feature], bins-2, labels=False)\n",
    "            \n",
    "    for feature in features_to_quantazie:\n",
    "        df[feature] = df[feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR\n",
       "396230    0\n",
       "215174    0\n",
       "427018    1\n",
       "237110    1\n",
       "442377    1\n",
       "Name: NAME_INCOME_TYPE, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['NAME_INCOME_TYPE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasil\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1164: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5242efec6f57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NAME_INCOME_TYPE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Businessman'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1164\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type comparison\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "train[train['NAME_INCOME_TYPE'] == 'Businessman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasil\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1164: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-fec454877c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfer_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-341017d3a593>\u001b[0m in \u001b[0;36mclip\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# lumping rare income types into a single category\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mindex1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NAME_INCOME_TYPE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Businessman'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mindex2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NAME_INCOME_TYPE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Maternity leave'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mindex3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NAME_INCOME_TYPE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Student'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1164\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type comparison\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "clip(train)\n",
    "clip(valid)\n",
    "clip(infer_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../input/train.csv', index=True)\n",
    "valid.to_csv('../input/valid.csv', index=True)\n",
    "infer_csv.to_csv('../input/infer.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After PCA I have identified the following features: Note these 10 features explain 95%+ from the variance in the dataset\n",
    "* AMT_CREDIT\n",
    "* AMT_GOODS_PRICE\n",
    "* AMT_ACTIVE_LOANS\n",
    "* AMT_OUTSTD_0_YEAR\n",
    "* AMT_OUTSTD_1_YEAR\n",
    "* AMT_OUTSTD_2_YEAR\n",
    "* AMT_OUTSTD_3_YEAR\n",
    "* AMT_OUTSTD_4_YEAR\n",
    "* AMT_OUTSTD_5_YEAR\n",
    "* DAYS_EMPLOYED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
