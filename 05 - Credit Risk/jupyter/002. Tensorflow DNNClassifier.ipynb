{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the engineered datasets\n",
    "df_train = pd.read_csv('../input/train.csv') # training set after train/test split\n",
    "df_valid = pd.read_csv('../input/valid.csv') # testing set after train/test split\n",
    "df_infer = pd.read_csv('../input/infer.csv') # inference set provided in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    35677\n",
       "1.0    33822\n",
       "4.0    29235\n",
       "9.0    26049\n",
       "8.0    25451\n",
       "0.0    23411\n",
       "2.0    22399\n",
       "5.0    19620\n",
       "3.0    17604\n",
       "7.0    12736\n",
       "Name: AMT_GOODS_PRICE, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['AMT_GOODS_PRICE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with the numerical features\n",
    "NUMERIC_FEATURES = [\n",
    "    'EXT_SOURCE_1',\n",
    "    'EXT_SOURCE_2',\n",
    "    'EXT_SOURCE_3',\n",
    "]\n",
    "\n",
    "# dictionary with the categorical features\n",
    "CATEGORICAL_FEATURES = [\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(key='CODE_GENDER', \n",
    "                                                              vocabulary_list=('M','F')),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(key='NAME_INCOME_TYPE', \n",
    "                                                              vocabulary_list=(\n",
    "                                                                  'Working',\n",
    "                                                                  'Commercial associate',\n",
    "                                                                  'Pensioner',\n",
    "                                                                  'State servant',\n",
    "                                                                  'OTHER'\n",
    "                                                              )),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(key='NAME_FAMILY_STATUS', \n",
    "                                                              vocabulary_list=(\n",
    "                                                                  'Married',\n",
    "                                                                  'Single / not married',\n",
    "                                                                  'Civil marriage',\n",
    "                                                                  'Separated',\n",
    "                                                                  'Widow'\n",
    "                                                              )),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(key='NAME_CONTRACT_TYPE', \n",
    "                                                              vocabulary_list=(\n",
    "                                                                  'Cash loans',\n",
    "                                                                  'Revolving loans'\n",
    "                                                              )),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(key='FLAG_OWN_CAR', \n",
    "                                                              vocabulary_list=(\n",
    "                                                                  'Y',\n",
    "                                                                  'N'\n",
    "                                                              )),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list(key='FLAG_OWN_REALTY', \n",
    "                                                              vocabulary_list=(\n",
    "                                                                  'Y',\n",
    "                                                                  'N'\n",
    "                                                              )),\n",
    "    tf.feature_column.categorical_column_with_identity(key='CNT_CHILDREN', num_buckets=5),\n",
    "    tf.feature_column.categorical_column_with_identity(key='CNT_FAM_MEMBERS', num_buckets=7),\n",
    "    #tf.feature_column.categorical_column_with_identity(key='AMT_REQ_CREDIT_BUREAU_HOUR', num_buckets=3),\n",
    "    #tf.feature_column.categorical_column_with_identity(key='AMT_REQ_CREDIT_BUREAU_DAY', num_buckets=3),\n",
    "    tf.feature_column.categorical_column_with_identity(key='AMT_REQ_CREDIT_BUREAU_WEEK', num_buckets=3),\n",
    "    tf.feature_column.categorical_column_with_identity(key='AMT_REQ_CREDIT_BUREAU_MON', num_buckets=11),\n",
    "    tf.feature_column.categorical_column_with_identity(key='AMT_REQ_CREDIT_BUREAU_QRT', num_buckets=7),\n",
    "    tf.feature_column.categorical_column_with_identity(key='AMT_REQ_CREDIT_BUREAU_YEAR', num_buckets=7),\n",
    "    tf.feature_column.categorical_column_with_identity(key='OBS_30_CNT_SOCIAL_CIRCLE', num_buckets=18),\n",
    "    tf.feature_column.categorical_column_with_identity(key='OBS_60_CNT_SOCIAL_CIRCLE', num_buckets=18),\n",
    "    tf.feature_column.categorical_column_with_identity(key='DEF_30_CNT_SOCIAL_CIRCLE', num_buckets=6),\n",
    "    tf.feature_column.categorical_column_with_identity(key='DEF_60_CNT_SOCIAL_CIRCLE', num_buckets=5),\n",
    "    tf.feature_column.categorical_column_with_identity(key='AMT_INCOME_TOTAL', num_buckets=10),\n",
    "    tf.feature_column.categorical_column_with_identity(key='AMT_CREDIT', num_buckets=10),\n",
    "    #tf.feature_column.categorical_column_with_identity(key='AMT_ANNUITY', num_buckets=10),\n",
    "    #tf.feature_column.categorical_column_with_identity(key='AMT_GOODS_PRICE', num_buckets=10),\n",
    "    tf.feature_column.categorical_column_with_identity(key='DAYS_BIRTH', num_buckets=10),\n",
    "    tf.feature_column.categorical_column_with_identity(key='DAYS_ID_PUBLISH', num_buckets=10),\n",
    "    tf.feature_column.categorical_column_with_identity(key='DAYS_LAST_PHONE_CHANGE', num_buckets=8),\n",
    "    tf.feature_column.categorical_column_with_identity(key='DAYS_REGISTRATION', num_buckets=10),\n",
    "    tf.feature_column.categorical_column_with_identity(key='OWN_CAR_AGE', num_buckets=10),\n",
    "    tf.feature_column.categorical_column_with_identity(key='REGION_POPULATION_RELATIVE', num_buckets=10)\n",
    "]\n",
    "\n",
    "# initializing the LABEL and INPUT_COLUMNS variables\n",
    "LABEL = 'TARGET'\n",
    "INPUT_COLUMNS = []\n",
    "\n",
    "# adding the numeric features to the tensorflow graph\n",
    "for feature in NUMERIC_FEATURES:\n",
    "    INPUT_COLUMNS.append(tf.feature_column.numeric_column(feature))\n",
    "    \n",
    "# adding the categorical features to the tensorflow graph\n",
    "for feature in CATEGORICAL_FEATURES:\n",
    "    INPUT_COLUMNS.append(tf.feature_column.indicator_column(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining an train input function which feeds the training pandas dataframe\n",
    "def input_fn_train(df, num_epochs):\n",
    "    '''\n",
    "    inputs:\n",
    "    df - training set after train/test split\n",
    "    \n",
    "    output:\n",
    "    minibatches of x,y\n",
    "    '''\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 400,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining an prediction input function which feeds the inference pandas dataframe\n",
    "def input_fn_eval(df, num_epochs):\n",
    "    '''\n",
    "    inputs:\n",
    "    df - testing set after train/test split\n",
    "    \n",
    "    output:\n",
    "    minibatches of x,y\n",
    "    '''\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining an prediction input function which feeds the inference pandas dataframe\n",
    "def input_fn_infer(df, num_epochs):\n",
    "    '''\n",
    "    inputs:\n",
    "    df - inference dataset provided in Kaggle\n",
    "    \n",
    "    output:\n",
    "    minibatches of x,None\n",
    "    '''\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = None,\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Log', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FD417AD2B0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 10 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input, not integer. key: AMT_REQ_CREDIT_BUREAU_HOUR dtype: <dtype: 'float64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d66000f1b13d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m                        throttle_secs = 10)  # evaluate every N seconds\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    437\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m   \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    517\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    648\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m           hooks=train_hooks)\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m       \u001b[1;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 843\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m--> 856\u001b[1;33m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m    345\u001b[0m           \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m           config=config)\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     super(DNNClassifier, self).__init__(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[1;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         input_layer_partitioner=input_layer_partitioner)\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     return head.create_estimator_spec(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[1;34m(features, mode)\u001b[0m\n\u001b[0;32m     89\u001b[0m         partitioner=input_layer_partitioner):\n\u001b[0;32m     90\u001b[0m       net = feature_column_lib.input_layer(\n\u001b[1;32m---> 91\u001b[1;33m           features=features, feature_columns=feature_columns)\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m       with variable_scope.variable_scope(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[0;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[1;32m--> 277\u001b[1;33m                                trainable, cols_to_vars)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             trainable=trainable)\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3300\u001b[0m     \u001b[1;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3301\u001b[0m     \u001b[1;31m# representation created by _transform_feature.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3302\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3304\u001b[0m   def _get_sequence_dense_tensor(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Transforming feature_column %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2100\u001b[1;33m     \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Column {} is not supported.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_transform_feature\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3229\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0mrank\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mknown\u001b[0m \u001b[0mat\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mbuilding\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m     \"\"\"\n\u001b[1;32m-> 3231\u001b[1;33m     \u001b[0mid_weight_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3232\u001b[0m     \u001b[0mid_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid_weight_pair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3233\u001b[0m     \u001b[0mweight_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid_weight_pair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_get_sparse_tensors\u001b[1;34m(self, inputs, weight_collections, trainable)\u001b[0m\n\u001b[0;32m   2935\u001b[0m   def _get_sparse_tensors(\n\u001b[0;32m   2936\u001b[0m       self, inputs, weight_collections=None, trainable=None):\n\u001b[1;32m-> 2937\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_CategoricalColumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIdWeightPair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Transforming feature_column %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2100\u001b[1;33m     \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Column {} is not supported.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_transform_feature\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2897\u001b[0m       raise ValueError(\n\u001b[0;32m   2898\u001b[0m           'Invalid input, not integer. key: {} dtype: {}'.format(\n\u001b[1;32m-> 2899\u001b[1;33m               self.key, input_tensor.dtype))\n\u001b[0m\u001b[0;32m   2900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'values'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input, not integer. key: AMT_REQ_CREDIT_BUREAU_HOUR dtype: <dtype: 'float64'>"
     ]
    }
   ],
   "source": [
    "OUTDIR = 'C:\\\\Log'\n",
    "\n",
    "file_writer = tf.summary.FileWriter(OUTDIR)\n",
    "\n",
    "estimator=tf.estimator.DNNClassifier(\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        hidden_units=[6,6,6,6], \n",
    "                        feature_columns=INPUT_COLUMNS, \n",
    "                        model_dir=OUTDIR,\n",
    "                        n_classes=2,\n",
    "                        optimizer=tf.train.AdamOptimizer(learning_rate=0.00001),\n",
    "                        dropout=0.2,\n",
    "                        loss_reduction='weighted_sum')\n",
    "\n",
    "train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = input_fn_train(df_train, 5),\n",
    "                       max_steps = 1000000)\n",
    "\n",
    "eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = input_fn_eval(df_valid, 5),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10)  # evaluate every N seconds\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
