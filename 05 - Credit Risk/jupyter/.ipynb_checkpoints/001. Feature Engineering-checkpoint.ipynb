{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.precision',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../input/application_train.csv.zip', compression='infer')\n",
    "infer_csv = pd.read_csv('../input/application_test.csv.zip', compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_csv, infer_csv], axis=0, ignore_index=False, sort=False)\n",
    "df.set_index('SK_ID_CURR',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rows(df):\n",
    "    \n",
    "    # removing 4 rows\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # removing 2 rows\n",
    "    df = df[df['NAME_FAMILY_STATUS'] != 'Unknown']\n",
    "    \n",
    "def drop_columns(df):\n",
    "    columns_to_drop = [\n",
    "        'FLAG_DOCUMENT_2',  # only 15 people provided this document and 4 are approved (nothing to learn from this feature)\n",
    "        'FLAG_DOCUMENT_4',  # only 25 people provided this document and all are approved (high bias toward 1)\n",
    "        'FLAG_DOCUMENT_7',  # only 59 people provided this document and 3 are approved (high bias towards 0)\n",
    "        'FLAG_DOCUMENT_10', # only 7 people provided this document and None are approved (high bias towards 0)\n",
    "        'FLAG_DOCUMENT_12', # only 2 people provided this document and None are approved (high bias towards 0)\n",
    "        'FLAG_DOCUMENT_17', # only 82 people provided this document and 2 are approved (high bias towards 0)\n",
    "        'FLAG_MOBIL',       # only 1 didn't provide this info and he is rejected (high bias towards 0)\n",
    "    ]\n",
    "    \n",
    "    for column in df.columns:\n",
    "        words = column.split('_')\n",
    "        if (words[-1].lower() == 'avg') or (words[-1].lower() == 'medi') or (words[-1].lower() == 'mode'):\n",
    "            columns_to_drop.append(column)\n",
    "            \n",
    "    df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "def clip(df):\n",
    "    # all people with more than 4 children are cliped to 4\n",
    "    df['CNT_CHILDREN'].clip(lower=0, upper=4, inplace=True)\n",
    "    \n",
    "    # all people with more than 6 fam. members are cliped to 6\n",
    "    df['CNT_FAM_MEMBERS'].clip(lower=0, upper=6, inplace=True) \n",
    "    \n",
    "    df['AMT_REQ_CREDIT_BUREAU_HOUR'].clip(lower=0, upper=2, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_DAY'].clip(lower=0, upper=2, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_WEEK'].clip(lower=0, upper=2, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_MON'].clip(lower=0, upper=10, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_QRT'].clip(lower=0, upper=6, inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_YEAR'].clip(lower=0, upper=6, inplace=True)\n",
    "    df['OBS_30_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=17, inplace=True)\n",
    "    df['OBS_60_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=17, inplace=True)\n",
    "    df['DEF_30_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=5, inplace=True)\n",
    "    df['DEF_60_CNT_SOCIAL_CIRCLE'].clip(lower=0, upper=4, inplace=True)\n",
    "    \n",
    "    # lumping rare income types into a single category\n",
    "    index1 = df[df['NAME_INCOME_TYPE'] == 'Businessman'].index\n",
    "    index2 = df[df['NAME_INCOME_TYPE'] == 'Maternity leave'].index\n",
    "    index3 = df[df['NAME_INCOME_TYPE'] == 'Student'].index\n",
    "    index4 = df[df['NAME_INCOME_TYPE'] == 'Unemployed'].index\n",
    "    \n",
    "    df.loc[index1,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    df.loc[index2,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    df.loc[index3,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    df.loc[index4,'NAME_INCOME_TYPE'] = 'OTHER'\n",
    "    \n",
    "def quantize(df, bins=10):\n",
    "    features_to_quantazie = [\n",
    "        'AMT_INCOME_TOTAL',\n",
    "        'AMT_CREDIT',\n",
    "        'AMT_ANNUITY',\n",
    "        'AMT_GOODS_PRICE',\n",
    "        'DAYS_BIRTH',\n",
    "        'DAYS_ID_PUBLISH',\n",
    "        'DAYS_LAST_PHONE_CHANGE',\n",
    "        'DAYS_REGISTRATION',\n",
    "        'OWN_CAR_AGE',\n",
    "        'REGION_POPULATION_RELATIVE'\n",
    "    ]\n",
    "    \n",
    "    for feature in features_to_quantazie:\n",
    "        if feature != 'DAYS_LAST_PHONE_CHANGE':\n",
    "            df[feature] = pd.qcut(df[feature], bins, labels=False)\n",
    "        else:\n",
    "            df[feature] = pd.qcut(df[feature], bins-2, labels=False)\n",
    "            \n",
    "    for feature in features_to_quantazie:\n",
    "        df[feature] = df[feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_df(df, value, func, labels, by='SK_ID_CURR', column=None):\n",
    "    \n",
    "    if column != None:\n",
    "        pivoted = df.pivot_table(index=by, \n",
    "                                 columns=column, \n",
    "                                 values=value, \n",
    "                                 aggfunc=func, \n",
    "                                 fill_value=0, \n",
    "                                 dropna=False)\n",
    "    else:\n",
    "        pivoted = df.pivot_table(index=by, \n",
    "                                 values=value, \n",
    "                                 aggfunc=func, \n",
    "                                 fill_value=0, \n",
    "                                 dropna=False)\n",
    "        \n",
    "    pivoted_df = pd.DataFrame(pivoted.to_records())\n",
    "    \n",
    "    pivoted_df.rename(columns=labels, inplace=True)\n",
    "    \n",
    "    return pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    \n",
    "    bureau = pd.read_csv('../input/bureau.csv.zip', compression='infer')\n",
    "    \n",
    "    labels = {\n",
    "          'Active'   : 'CNT_ACTIVE_LOANS',\n",
    "          'Bad debt' : 'CNT_BAD_DEBT',\n",
    "          'Closed'   : 'CNT_CLOSED_DEBT',\n",
    "          'Sold'     : 'CNT_SOLD_DEBT'\n",
    "         }\n",
    "    \n",
    "    cnt_loans = aggregate_df(df=bureau, value='CREDIT_TYPE', column='CREDIT_ACTIVE', func='count', labels=labels)\n",
    "    \n",
    "    del bureau\n",
    "    \n",
    "    previous = pd.read_csv('../input/previous_application.csv.zip', compression='infer')\n",
    "    \n",
    "    labels = {\n",
    "          'Approved'     : 'CNT_LOANS_APPROVED',\n",
    "          'Canceled'     : 'CNT_LOANS_CANCELLED',\n",
    "          'Refused'      : 'CNT_LOANS_REFUSED',\n",
    "          'Unused offer' : 'CNT_UNUSED_OFFERS'\n",
    "         }\n",
    "\n",
    "    cnt_prev_loans = aggregate_df(df=previous, \n",
    "                              value='NAME_CONTRACT_TYPE', column='NAME_CONTRACT_STATUS', func='count', labels=labels)\n",
    "    \n",
    "    del previous\n",
    "    \n",
    "    credit_card_balance = pd.read_csv('../input/credit_card_balance.csv.zip', compression='infer')\n",
    "    \n",
    "    labels = {\n",
    "          'CNT_DRAWINGS_CURRENT'   : 'CNT_CC_DRAWINGS'\n",
    "         }\n",
    "\n",
    "    cc_draw_cnt = aggregate_df(df=credit_card_balance,\n",
    "                          value='CNT_DRAWINGS_CURRENT', func='sum', labels=labels)\n",
    "    \n",
    "    del credit_card_balance\n",
    "    \n",
    "    df = pd.concat([df, cnt_loans], axis=1, join='outer', join_axes=[df.index])\n",
    "    df = pd.concat([df, cnt_prev_loans], axis=1, join='outer', join_axes=[df.index])\n",
    "    df = pd.concat([df, cc_draw_cnt], axis=1, join='outer', join_axes=[df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_NaN(df):\n",
    "    df['AMT_REQ_CREDIT_BUREAU_YEAR'].fillna(value=0,inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_QRT'].fillna(value=0,inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_MON'].fillna(value=0,inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_WEEK'].fillna(value=0,inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_DAY'].fillna(value=0,inplace=True)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_HOUR'].fillna(value=0,inplace=True)\n",
    "    df['AMT_GOODS_PRICE'].fillna(value=0,inplace=True)\n",
    "    df['DAYS_EMPLOYED'].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_NaN(df)     # 1\n",
    "add_features(df) # 2\n",
    "drop_columns(df) # 3\n",
    "delete_rows(df)  # 4\n",
    "quantize(df)     # 5\n",
    "clip(df)         # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_csv = df[df['TARGET'].isna() == False]\n",
    "infer_csv = df[df['TARGET'].isna() == True]\n",
    "\n",
    "infer_csv.drop('TARGET', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_csv, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0).to_csv('../input/train.csv', index=True)\n",
    "test.fillna(0).to_csv('../input/valid.csv', index=True)\n",
    "infer_csv.fillna(0).to_csv('../input/infer.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
