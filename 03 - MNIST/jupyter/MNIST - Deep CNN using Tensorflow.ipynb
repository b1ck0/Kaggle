{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# required for building the CNN\n",
    "import tensorflow as tf\n",
    "\n",
    "# required for splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('../input/train.csv')\n",
    "test_csv = pd.read_csv('../input/test.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the pixel and label data into a separate variables, required for our machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_csv.drop('label', axis=1).values.tolist()\n",
    "test_images = test_csv.values.tolist()\n",
    "\n",
    "train_images = [np.array(pixels, dtype='int64') for pixels in train_images]\n",
    "test_images = [np.array(pixels, dtype='int64') for pixels in test_images]\n",
    "\n",
    "train_csv['pixels'] = train_images\n",
    "test_csv['pixels'] = test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining wrapper functions for Tensorflow methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    '''\n",
    "    method to initialize the weights of our NN using normal distribution with mean=0 and std=0.1\n",
    "    '''\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1, seed=0)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    '''\n",
    "    method to initialize the bias of our NN using constant value=0.1 for all nodes\n",
    "    '''\n",
    "    init_bias_vals = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x,W,strides):\n",
    "    '''\n",
    "    wrapper method to perform a 2D convolution\n",
    "    x - input values tensor [batches,height,width,channels]\n",
    "    W - filter tensor [height,width,channels in, channels out]\n",
    "    strides - step vector for the filter window [1,2,2,1] - reduces h and w by 2\n",
    "    '''\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "\n",
    "def max_pool(x, shape, strides):\n",
    "    '''\n",
    "    wrapper method to perform 2x2 max pooling \n",
    "    ksize - window size vector\n",
    "    strides - step vector for the pooling window [1,2,2,1] - reduces h and w by 2\n",
    "    '''\n",
    "    return tf.nn.max_pool(x, ksize=shape, strides=strides, padding='SAME')\n",
    "\n",
    "def convolutional_layer(x, shape, strides):\n",
    "    '''\n",
    "    method to define a convolutional layer in our NN\n",
    "    '''\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    \n",
    "    return tf.nn.relu(conv2d(x,W,strides)+b)\n",
    "\n",
    "def fully_connected_layer(layer,size):\n",
    "    '''\n",
    "    method to define a fully connected layer in our NN\n",
    "    '''\n",
    "    layer_size = int(layer.get_shape()[1])\n",
    "    W = init_weights([layer_size, size])\n",
    "    b = init_bias([size])\n",
    "    \n",
    "    return tf.matmul(layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Deep CNN in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a placeholder for our pixel data [batch_size,height,width]\n",
    "x = tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
    "\n",
    "# defining a placeholder for our label data [batch_suze,number of classification classes]\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10])\n",
    "\n",
    "# defining a placeholder storing the holding probability for the drop-out \n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# defining the first layer of the ANN\n",
    "## kernel size: 6x6\n",
    "## image size input: 28x28x1\n",
    "## image size output: 28x28x32\n",
    "layer_1 = convolutional_layer(x, shape=[6,6,1,32], strides=[1,1,1,1])\n",
    "\n",
    "# defining the second layer of the ANN\n",
    "## kernel size: 2x2\n",
    "## image size input: 28x28x32\n",
    "## image size output: 14x14x32\n",
    "layer_2 = max_pool(layer_1, shape=[1,2,2,1], strides=[1,2,2,1])\n",
    "\n",
    "# defining the third layer of the ANN\n",
    "## kernel size: 4x4\n",
    "## image size input: 14x14x32\n",
    "## image size output: 14x14x64\n",
    "layer_3 = convolutional_layer(layer_2, shape=[4,4,32,64], strides=[1,1,1,1])\n",
    "\n",
    "# defining the fourth layer of the ANN\n",
    "## kernel size: 2x2\n",
    "## image size input: 14x14x64\n",
    "## image size output: 7x7x64\n",
    "layer_4 = max_pool(layer_3, shape=[1,2,2,1], strides=[1,2,2,1])\n",
    "\n",
    "# defining the fifth layer of the ANN\n",
    "## kernel size: 3x3\n",
    "## image size input: 7x7x64\n",
    "## image size output: 7x7x128\n",
    "layer_5 = convolutional_layer(layer_4, shape=[3,3,64,128], strides=[1,1,1,1])\n",
    "\n",
    "# reshaping the last layer into [batch_size, height*width*channels]\n",
    "flattened = tf.reshape(layer_5,[-1,7*7*128])\n",
    "\n",
    "# defining the sixth layer of the ANN\n",
    "## neuron count: 128\n",
    "layer_6 = fully_connected_layer(flattened,1024)\n",
    "\n",
    "# neuron drop-out for the last layer\n",
    "layer_6_dropout = tf.nn.dropout(layer_6, keep_prob=hold_prob)\n",
    "\n",
    "# getting the prediction from the fully connected layer\n",
    "## note: the results will not be in softmax format but it is also not really necessary\n",
    "## neuron count: 10 (equal to the number of classes we need to classify)\n",
    "y_pred = fully_connected_layer(layer_6_dropout,10)\n",
    "\n",
    "# defining a loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "\n",
    "# defining an optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# initializing the global variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the batch managers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "def transform(pixels):\n",
    "    return pixels.reshape((28, 28, 1))\n",
    "\n",
    "def one_hot_encode(label, num_classes=10):\n",
    "    encoded = np.zeros(num_classes)\n",
    "    encoded[label] = 1\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "class Manager():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \n",
    "        self.i = 0\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        self.pixels = np.zeros( (len(df['pixels']), 28*28) )\n",
    "        self.labels_raw = []\n",
    "        \n",
    "        self.pixels = [pixels for pixels in self.df['pixels']]\n",
    "        \n",
    "        self.num_classes = 10\n",
    "    \n",
    "    def next_batch_train(self, batch_size):\n",
    "        \n",
    "        self.labels_raw = [label for label in self.df['label']]\n",
    "        \n",
    "        x = np.zeros(shape=(batch_size,28,28))\n",
    "        y = np.zeros(shape=(batch_size,self.num_classes))\n",
    "        \n",
    "        x = [transform(pixels) for pixels in self.pixels[self.i:self.i+batch_size]]\n",
    "        y = [one_hot_encode(label, self.num_classes) for label in self.labels_raw[self.i:self.i+batch_size]]\n",
    "        \n",
    "        self.i = (self.i+batch_size) % len(self.pixels)\n",
    "        \n",
    "        return x,y\n",
    "    \n",
    "    def next_batch_predict(self, batch_size):\n",
    "        \n",
    "        x = np.zeros(shape=(batch_size,28,28))\n",
    "        \n",
    "        x = [transform(pixels) for pixels in self.pixels[self.i:self.i+batch_size]]\n",
    "        \n",
    "        self.i = (self.i+batch_size) % len(self.pixels)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def store_raw_labels(self, raw_labels):\n",
    "        self.labels_raw.append(softmax(raw_labels))\n",
    "        \n",
    "    def transform_data(self):\n",
    "        self.labels_raw = [item for sublist in self.labels_raw for item in sublist]\n",
    "        self.labels_raw = np.array(self.labels_raw)\n",
    "        self.labels = np.argmax(self.labels_raw, axis=1)\n",
    "        self.confidence = np.amax(self.labels_raw, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Manager(train_csv)\n",
    "predictor = Manager(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Training and Prediction using Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on batch 0, progress 0.00% ----> Accuracy on the current batch is: 22.32%\n",
      "Currently on batch 25, progress 5.00% ----> Accuracy on the current batch is: 91.31%\n",
      "Currently on batch 50, progress 10.00% ----> Accuracy on the current batch is: 95.00%\n",
      "Currently on batch 75, progress 15.00% ----> Accuracy on the current batch is: 96.55%\n",
      "Currently on batch 100, progress 20.00% ----> Accuracy on the current batch is: 97.32%\n",
      "Currently on batch 125, progress 25.00% ----> Accuracy on the current batch is: 98.15%\n",
      "Currently on batch 150, progress 30.00% ----> Accuracy on the current batch is: 98.51%\n",
      "Currently on batch 175, progress 35.00% ----> Accuracy on the current batch is: 98.75%\n",
      "Currently on batch 200, progress 40.00% ----> Accuracy on the current batch is: 98.81%\n",
      "Currently on batch 225, progress 45.00% ----> Accuracy on the current batch is: 99.11%\n",
      "Currently on batch 250, progress 50.00% ----> Accuracy on the current batch is: 99.29%\n",
      "Currently on batch 275, progress 55.00% ----> Accuracy on the current batch is: 99.46%\n",
      "Currently on batch 300, progress 60.00% ----> Accuracy on the current batch is: 99.64%\n",
      "Currently on batch 325, progress 65.00% ----> Accuracy on the current batch is: 99.70%\n",
      "Currently on batch 350, progress 70.00% ----> Accuracy on the current batch is: 99.46%\n",
      "Currently on batch 375, progress 75.00% ----> Accuracy on the current batch is: 99.70%\n",
      "Currently on batch 400, progress 80.00% ----> Accuracy on the current batch is: 99.82%\n",
      "Currently on batch 425, progress 85.00% ----> Accuracy on the current batch is: 99.82%\n",
      "Currently on batch 450, progress 90.00% ----> Accuracy on the current batch is: 99.70%\n",
      "Currently on batch 475, progress 95.00% ----> Accuracy on the current batch is: 99.82%\n",
      "Predicting on batch 0\n",
      "Predicting on batch 1\n",
      "Predicting on batch 2\n",
      "Predicting on batch 3\n",
      "Predicting on batch 4\n",
      "Predicting on batch 5\n",
      "Predicting on batch 6\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # initializing the global variables within the session\n",
    "    sess.run(init)\n",
    "    \n",
    "    # defining 20 epochs for training = (25 batches x 1680 images) x 20\n",
    "    N = 25*20\n",
    "        \n",
    "    for batch in range(N):\n",
    "        \n",
    "        # getting the current batch of images and labels\n",
    "        images, labels = trainer.next_batch_train(batch_size = 1680)\n",
    "        \n",
    "        # training using the current batch, \n",
    "        sess.run(train, feed_dict={x: images, y_true: labels, hold_prob: 0.25})\n",
    "        \n",
    "        # on each epoch I will print the accuracy on the current batch and the training progress\n",
    "        if batch % 25 == 0:\n",
    "            \n",
    "            # calculating the accuracy on the current batch\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "            accuracy = sess.run(acc,feed_dict={x: images, y_true: labels, hold_prob: 1.0})\n",
    "\n",
    "            print('Currently on batch {}, progress {:.2%} ----> Accuracy on the current batch is: {:.2%}'\n",
    "                .format(batch, batch/N, accuracy))\n",
    "            \n",
    "    # once the training is done I will perform prediction on the testing set\n",
    "    \n",
    "    N = 7\n",
    "    \n",
    "    for batch in range(N):\n",
    "        \n",
    "        print('Predicting on batch {}'.format(batch))\n",
    "        \n",
    "        images = predictor.next_batch_predict(batch_size = 4000)\n",
    "        \n",
    "        prediction_batch = sess.run(y_pred, feed_dict={x: images, hold_prob: 1.0})\n",
    "        predictor.store_raw_labels(prediction_batch)\n",
    "        \n",
    "    predictor.transform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['ImageId'] = range(1, 28001, 1)\n",
    "submission['Label'] = predictor.labels\n",
    "submission.set_index('ImageId', inplace=True)\n",
    "submission.to_csv('submission-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
