{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# required for building the CNN\n",
    "import tensorflow as tf\n",
    "\n",
    "# required for splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('../input/train.csv')\n",
    "test_csv = pd.read_csv('../input/test.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the pixel and label data into a separate variables, required for our machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_csv.drop('label', axis=1).values.tolist()\n",
    "test_images = test_csv.values.tolist()\n",
    "\n",
    "train_images = [np.array(pixels, dtype='int64') for pixels in train_images]\n",
    "test_images = [np.array(pixels, dtype='int64') for pixels in test_images]\n",
    "\n",
    "train_csv['pixels'] = train_images\n",
    "test_csv['pixels'] = test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16d1fbf4908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_csv.loc[1011]['pixels'].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining wrapper functions for Tensorflow methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    '''\n",
    "    method to initialize the weights of our NN using normal distribution with mean=0 and std=0.1\n",
    "    '''\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1, seed=0)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    '''\n",
    "    method to initialize the bias of our NN using constant value=0.1 for all nodes\n",
    "    '''\n",
    "    init_bias_vals = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x,W,strides):\n",
    "    '''\n",
    "    wrapper method to perform a 2D convolution\n",
    "    x - input values tensor [batches,height,width,channels]\n",
    "    W - filter tensor [height,width,channels in, channels out]\n",
    "    strides - step vector for the filter window [1,2,2,1] - reduces h and w by 2\n",
    "    '''\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "\n",
    "def max_pool(x, shape, strides):\n",
    "    '''\n",
    "    wrapper method to perform 2x2 max pooling \n",
    "    ksize - window size vector\n",
    "    strides - step vector for the pooling window [1,2,2,1] - reduces h and w by 2\n",
    "    '''\n",
    "    return tf.nn.max_pool(x, ksize=shape, strides=strides, padding='SAME')\n",
    "\n",
    "def convolutional_layer(x, shape, strides):\n",
    "    '''\n",
    "    method to define a convolutional layer in our NN\n",
    "    '''\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    \n",
    "    return tf.nn.relu(conv2d(x,W,strides)+b)\n",
    "\n",
    "def fully_connected_layer(layer,size):\n",
    "    '''\n",
    "    method to define a fully connected layer in our NN\n",
    "    '''\n",
    "    layer_size = int(layer.get_shape()[1])\n",
    "    W = init_weights([layer_size, size])\n",
    "    b = init_bias([size])\n",
    "    \n",
    "    return tf.matmul(layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Deep CNN in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a placeholder for our pixel data [batch_size,height,width]\n",
    "x = tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
    "\n",
    "# defining a placeholder for our label data [batch_suze,number of classification classes]\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10])\n",
    "\n",
    "# defining a placeholder storing the holding probability for the drop-out \n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# defining the first layer of the ANN\n",
    "## kernel size: 6x6\n",
    "## image size input: 28x28x1\n",
    "## image size output: 28x28x10\n",
    "layer_1 = convolutional_layer(x, shape=[22,22,1,10], strides=[1,1,1,1])\n",
    "\n",
    "# defining the second layer of the ANN\n",
    "## kernel size: 2x2\n",
    "## image size input: 28x28x10\n",
    "## image size output: 28x28x14\n",
    "layer_2 = convolutional_layer(layer_1, shape=[10,20,10,14], strides=[1,1,1,1])\n",
    "\n",
    "# defining the third layer of the ANN\n",
    "## kernel size: 4x4\n",
    "## image size input: 14x14x32\n",
    "## image size output: 14x14x64\n",
    "####layer_3 = convolutional_layer(layer_2, shape=[4,4,32,64], strides=[1,1,1,1])\n",
    "\n",
    "# defining the fourth layer of the ANN\n",
    "## kernel size: 2x2\n",
    "## image size input: 14x14x64\n",
    "## image size output: 7x7x64\n",
    "###layer_4 = convolutional_layer(layer_3, shape=[2,2,64,64], strides=[1,2,2,1])\n",
    "\n",
    "# defining the fifth layer of the ANN\n",
    "## kernel size: 3x3\n",
    "## image size input: 7x7x64\n",
    "## image size output: 7x7x128\n",
    "###layer_5 = convolutional_layer(layer_4, shape=[2,2,64,64], strides=[1,1,1,1])\n",
    "\n",
    "# reshaping the last layer into [batch_size, height*width*channels]\n",
    "flattened = tf.reshape(layer_2,[-1,28*28*14])\n",
    "\n",
    "# defining the sixth layer of the ANN\n",
    "## neuron count: 128\n",
    "layer_6 = fully_connected_layer(flattened,512)\n",
    "\n",
    "# neuron drop-out for the last layer\n",
    "layer_6_dropout = tf.nn.dropout(layer_6, keep_prob=hold_prob)\n",
    "\n",
    "# getting the prediction from the fully connected layer\n",
    "## note: the results will not be in softmax format but it is also not really necessary\n",
    "## neuron count: 10 (equal to the number of classes we need to classify)\n",
    "y_pred = fully_connected_layer(layer_6_dropout,10)\n",
    "\n",
    "# defining a loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "\n",
    "# defining an optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# initializing the global variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the batch managers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "def transform(pixels):\n",
    "    return pixels.reshape((28, 28, 1))/255\n",
    "\n",
    "def one_hot_encode(label, num_classes=10):\n",
    "    encoded = np.zeros(num_classes)\n",
    "    encoded[label] = 1\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "class Manager():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \n",
    "        self.i = 0\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        self.pixels = np.zeros( (len(df['pixels']), 28*28) )\n",
    "        self.labels_raw = []\n",
    "        \n",
    "        self.pixels = [pixels for pixels in self.df['pixels']]\n",
    "        \n",
    "        self.num_classes = 10\n",
    "    \n",
    "    def next_batch_train(self, batch_size):\n",
    "        \n",
    "        self.labels_raw = [label for label in self.df['label']]\n",
    "        \n",
    "        x = np.zeros(shape=(batch_size,28,28))\n",
    "        y = np.zeros(shape=(batch_size,self.num_classes))\n",
    "        \n",
    "        x = [transform(pixels) for pixels in self.pixels[self.i:self.i+batch_size]]\n",
    "        y = [one_hot_encode(label, self.num_classes) for label in self.labels_raw[self.i:self.i+batch_size]]\n",
    "        \n",
    "        self.i = (self.i+batch_size) % len(self.pixels)\n",
    "        \n",
    "        return x,y\n",
    "    \n",
    "    def next_batch_predict(self, batch_size):\n",
    "        \n",
    "        x = np.zeros(shape=(batch_size,28,28))\n",
    "        \n",
    "        x = [transform(pixels) for pixels in self.pixels[self.i:self.i+batch_size]]\n",
    "        \n",
    "        self.i = (self.i+batch_size) % len(self.pixels)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def store_raw_labels(self, raw_labels):\n",
    "        self.labels_raw.append(softmax(raw_labels))\n",
    "        \n",
    "    def transform_data(self):\n",
    "        self.labels_raw = [item for sublist in self.labels_raw for item in sublist]\n",
    "        self.labels_raw = np.array(self.labels_raw)\n",
    "        self.labels = np.argmax(self.labels_raw, axis=1)\n",
    "        self.confidence = np.amax(self.labels_raw, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Manager(train_csv)\n",
    "predictor = Manager(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Training and Prediction using Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on batch 0, progress 0.00% ----> Accuracy on the current batch is: 20.18%\n",
      "Currently on batch 25, progress 2.00% ----> Accuracy on the current batch is: 80.18%\n",
      "Currently on batch 50, progress 4.00% ----> Accuracy on the current batch is: 90.12%\n",
      "Currently on batch 75, progress 6.00% ----> Accuracy on the current batch is: 93.39%\n",
      "Currently on batch 100, progress 8.00% ----> Accuracy on the current batch is: 93.93%\n",
      "Currently on batch 125, progress 10.00% ----> Accuracy on the current batch is: 95.12%\n",
      "Currently on batch 150, progress 12.00% ----> Accuracy on the current batch is: 95.95%\n",
      "Currently on batch 175, progress 14.00% ----> Accuracy on the current batch is: 96.25%\n",
      "Currently on batch 200, progress 16.00% ----> Accuracy on the current batch is: 96.85%\n",
      "Currently on batch 225, progress 18.00% ----> Accuracy on the current batch is: 97.14%\n",
      "Currently on batch 250, progress 20.00% ----> Accuracy on the current batch is: 97.62%\n",
      "Currently on batch 275, progress 22.00% ----> Accuracy on the current batch is: 98.10%\n",
      "Currently on batch 300, progress 24.00% ----> Accuracy on the current batch is: 98.27%\n",
      "Currently on batch 325, progress 26.00% ----> Accuracy on the current batch is: 98.51%\n",
      "Currently on batch 350, progress 28.00% ----> Accuracy on the current batch is: 98.63%\n",
      "Currently on batch 375, progress 30.00% ----> Accuracy on the current batch is: 98.75%\n",
      "Currently on batch 400, progress 32.00% ----> Accuracy on the current batch is: 98.99%\n",
      "Currently on batch 425, progress 34.00% ----> Accuracy on the current batch is: 99.17%\n",
      "Currently on batch 450, progress 36.00% ----> Accuracy on the current batch is: 99.11%\n",
      "Currently on batch 475, progress 38.00% ----> Accuracy on the current batch is: 99.29%\n",
      "Currently on batch 500, progress 40.00% ----> Accuracy on the current batch is: 99.05%\n",
      "Currently on batch 525, progress 42.00% ----> Accuracy on the current batch is: 99.29%\n",
      "Currently on batch 550, progress 44.00% ----> Accuracy on the current batch is: 99.40%\n",
      "Currently on batch 575, progress 46.00% ----> Accuracy on the current batch is: 99.58%\n",
      "Currently on batch 600, progress 48.00% ----> Accuracy on the current batch is: 99.46%\n",
      "Currently on batch 625, progress 50.00% ----> Accuracy on the current batch is: 99.76%\n",
      "Currently on batch 650, progress 52.00% ----> Accuracy on the current batch is: 99.76%\n",
      "Currently on batch 675, progress 54.00% ----> Accuracy on the current batch is: 99.76%\n",
      "Currently on batch 700, progress 56.00% ----> Accuracy on the current batch is: 99.82%\n",
      "Currently on batch 725, progress 58.00% ----> Accuracy on the current batch is: 99.94%\n",
      "Currently on batch 750, progress 60.00% ----> Accuracy on the current batch is: 99.82%\n",
      "Currently on batch 775, progress 62.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 800, progress 64.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 825, progress 66.00% ----> Accuracy on the current batch is: 99.88%\n",
      "Currently on batch 850, progress 68.00% ----> Accuracy on the current batch is: 99.88%\n",
      "Currently on batch 875, progress 70.00% ----> Accuracy on the current batch is: 99.88%\n",
      "Currently on batch 900, progress 72.00% ----> Accuracy on the current batch is: 99.94%\n",
      "Currently on batch 925, progress 74.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 950, progress 76.00% ----> Accuracy on the current batch is: 99.94%\n",
      "Currently on batch 975, progress 78.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1000, progress 80.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1025, progress 82.00% ----> Accuracy on the current batch is: 99.94%\n",
      "Currently on batch 1050, progress 84.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1075, progress 86.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1100, progress 88.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1125, progress 90.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1150, progress 92.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1175, progress 94.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1200, progress 96.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Currently on batch 1225, progress 98.00% ----> Accuracy on the current batch is: 100.00%\n",
      "Predicting on batch 0\n",
      "Predicting on batch 1\n",
      "Predicting on batch 2\n",
      "Predicting on batch 3\n",
      "Predicting on batch 4\n",
      "Predicting on batch 5\n",
      "Predicting on batch 6\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # initializing the global variables within the session\n",
    "    sess.run(init)\n",
    "    \n",
    "    # defining 20 epochs for training = (25 batches x 1680 images) x 20\n",
    "    N = 25*50\n",
    "        \n",
    "    for batch in range(N):\n",
    "        \n",
    "        # getting the current batch of images and labels\n",
    "        images, labels = trainer.next_batch_train(batch_size = 1680)\n",
    "        \n",
    "        # training using the current batch, \n",
    "        sess.run(train, feed_dict={x: images, y_true: labels, hold_prob: 0.50})\n",
    "        \n",
    "        # on each epoch I will print the accuracy on the current batch and the training progress\n",
    "        if batch % 25 == 0:\n",
    "            \n",
    "            # calculating the accuracy on the current batch\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "            accuracy = sess.run(acc,feed_dict={x: images, y_true: labels, hold_prob: 1.0})\n",
    "\n",
    "            print('Currently on batch {}, progress {:.2%} ----> Accuracy on the current batch is: {:.2%}'\n",
    "                .format(batch, batch/N, accuracy))\n",
    "            \n",
    "    # once the training is done I will perform prediction on the testing set\n",
    "    \n",
    "    N = 7\n",
    "    \n",
    "    for batch in range(N):\n",
    "        \n",
    "        print('Predicting on batch {}'.format(batch))\n",
    "        \n",
    "        images = predictor.next_batch_predict(batch_size = 4000)\n",
    "        \n",
    "        prediction_batch = sess.run(y_pred, feed_dict={x: images, hold_prob: 1.0})\n",
    "        predictor.store_raw_labels(prediction_batch)\n",
    "        \n",
    "    predictor.transform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['ImageId'] = range(1, 28001, 1)\n",
    "submission['Label'] = predictor.labels\n",
    "submission.set_index('ImageId', inplace=True)\n",
    "submission.to_csv('submission-04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
